{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd28e23-5c5c-4b59-aeba-81ff2f7980af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys  \n",
    "sys.path.insert(0, '..')\n",
    "import time\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from util.plots import show_plot\n",
    "import pandas as pd\n",
    "\n",
    "feature = pd.read_csv('../data/feature_nirspec100.csv').values\n",
    "label = pd.read_csv('../data/label_nirspec100.csv').values\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c889f6c-ead4-4125-893d-a1af5de2c0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random data\n",
    "p = [4826, 31757, 25834, 26607, 37618, 16953, 1633, 38559, 16174, 6779, 28881, 14980, 38729, 13816, 32933, 7992, 39395, 3649, 9174, 39568, 18124, 21122, 7959, 15201, 31648, 39339, 29350, 37429, 13912, 24092, 10823, 32187, 12371, 25361, 5640, 25517, 38293, 18361, 2025, 24981, 34470, 2797, 5242, 33505, 25206, 23115, 11510, 28940, 16147, 14488, 6678, 18509, 16665, 30961, 31126, 29867, 39406, 1107, 19318, 29004, 15840, 36030, 34252, 16743, 17627, 8950, 25917, 31001, 299, 8428, 39252, 28270, 17296, 7729, 14925, 345, 23389, 23128, 14290, 37979, 21191, 21253, 13476, 9408, 16741, 26915, 34880, 16170, 38485, 38943, 13480, 20817, 23309, 19511, 9810, 34506, 2270, 37415, 206, 19076]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0d3cf9-5b28-4c55-832b-5c3074606249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best data\n",
    "p = [7, 17, 21, 48, 54, 60, 66, 74, 88, 90, 95, 110, 111, 112, 118, 140, 160, 170, 171, 174, 197, 202, 206, 217, 220, 241, 248, 260, 274, 287, 307, 311, 314, 316, 322, 328, 341, 353, 355, 361, 365, 373, 376, 384, 385, 386, 389, 390, 393, 398, 403, 406, 418, 422, 423, 427, 433, 434, 451, 452, 484, 487, 499, 509, 511, 516, 531, 538, 543, 554, 578, 588, 594, 597, 610, 614, 615, 618, 629, 642, 652, 669, 677, 678, 688, 692, 700, 705, 709, 717, 722, 725, 731, 734, 740, 745, 757, 759, 760, 775]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a37f973-b957-4e59-9573-b647e96ab537",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = feature[p]\n",
    "train_label = label[p]\n",
    "test_feature = feature[50000:]\n",
    "test_label = label[50000:]\n",
    "features_and_labels = list(zip(train_feature, train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ece1f2-7e53-4f55-8c3d-cc0580448b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.MeanSquaredError()\n",
    "layers_available_for_evolution = (keras.layers.Dense,)\n",
    "\n",
    "layers_format = [(keras.layers.InputLayer, [198]),\n",
    "                 (keras.layers.Dense, 150, 'relu'),\n",
    "                 (keras.layers.Dense, 44, 'relu'),\n",
    "                 (keras.layers.Dense, 12, 'relu')]\n",
    "\n",
    "\n",
    "class Individual:\n",
    "    def __init__(self, layers, loss, optimizer='Adam', weights=None, biases=None):\n",
    "        self.model = keras.Sequential()\n",
    "\n",
    "        layer_instance = layers[0][0](input_shape=layers[0][1])\n",
    "        self.model.add(layer_instance)\n",
    "\n",
    "        i = 0\n",
    "        for layer_data in layers[1:]:\n",
    "            if layer_data[0] == keras.layers.Dense:\n",
    "                layer_instance = layer_data[0](units=layer_data[1], activation=layer_data[2],\n",
    "                                               kernel_initializer=tf.initializers.constant(weights[i].numpy())\n",
    "                                               if weights else 'glorot_uniform',\n",
    "                                               bias_initializer=tf.initializers.constant(biases[i].numpy())\n",
    "                                               if biases else 'zeros')\n",
    "                i += 1\n",
    "            elif layer_data[0] == keras.layers.Dropout:\n",
    "                layer_instance = layer_data[0](rate=layer_data[1])\n",
    "\n",
    "            self.model.add(layer_instance)\n",
    "\n",
    "        self.model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "    @staticmethod\n",
    "    def weights_and_biases(model):\n",
    "        w = [None for i in range(len(model.layers))\n",
    "             if type(model.layers[i]) in layers_available_for_evolution]\n",
    "        b = [None for _ in range(len(w))]\n",
    "\n",
    "        i = 0\n",
    "        for layer in model.layers:\n",
    "            if type(layer) not in layers_available_for_evolution:\n",
    "                continue\n",
    "            w[i], b[i] = layer.trainable_weights\n",
    "            i += 1\n",
    "\n",
    "        return w, b\n",
    "\n",
    "    def assign(self, individual):\n",
    "        w, b = Individual.weights_and_biases(individual.model)\n",
    "        for i, layer in enumerate(self.model.layers):\n",
    "            weights = layer.trainable_weights[0]\n",
    "            indexes = np.argwhere(np.random.random(size=weights.shape) < 2)\n",
    "            weights.scatter_nd_update(indexes, w[i].numpy().reshape((len(indexes),)))\n",
    "\n",
    "            biases = layer.trainable_weights[1]\n",
    "            indexes = np.argwhere(np.random.random(size=biases.shape) < 2)\n",
    "            biases.scatter_nd_update(indexes, b[i].numpy().reshape((len(indexes),)))\n",
    "        return self\n",
    "\n",
    "\n",
    "def replace(individual, interval_w=(-1, 1), interval_b=(-1, 1), uniform_w=False, uniform_b=False):\n",
    "    for layer in individual.model.layers:\n",
    "        if type(layer) not in layers_available_for_evolution:\n",
    "            continue\n",
    "\n",
    "        weights = layer.trainable_weights[0]\n",
    "        indexes = np.argwhere(np.random.random(size=weights.shape) < 2)\n",
    "        f = np.random.uniform if uniform_w else np.random.normal\n",
    "        weights.scatter_nd_update(indexes, f(*interval_w, size=(len(indexes),)))\n",
    "\n",
    "        biases = layer.trainable_weights[1]\n",
    "        indexes = np.argwhere(np.random.random(size=biases.shape) < 2)\n",
    "        f = np.random.uniform if uniform_b else np.random.normal\n",
    "        biases.scatter_nd_update(indexes, f(*interval_b, size=(len(indexes),)))\n",
    "\n",
    "\n",
    "def evaluate(individual, features, labels):\n",
    "    return individual.model.evaluate(features, labels, batch_size=3000)\n",
    "\n",
    "\n",
    "def pure_random_search(iterations, t=None):\n",
    "    nn = Individual(layers_format, loss)\n",
    "    best_nn = [evaluate(nn, train_feature, train_label), Individual(layers_format, loss).assign(nn)]\n",
    "    i = 1\n",
    "    start = time.time()\n",
    "    while i < iterations or (t is not None and time.time() - start < t):\n",
    "        replace(nn, (0.0, 0.15), (0, 0.15), uniform_w=False, uniform_b=False)\n",
    "        loss_value = evaluate(nn, train_feature, train_label)\n",
    "        if loss_value < best_nn[0]:\n",
    "            best_nn[0] = loss_value\n",
    "            best_nn[1].assign(nn)\n",
    "        i += 1\n",
    "    print(i)\n",
    "    return best_nn\n",
    "\n",
    "\n",
    "def get_random_samples_in_n_sphere(n, r, nr_val):\n",
    "    x = np.random.normal(size=(nr_val, n))\n",
    "    u = np.random.random((nr_val, 1))\n",
    "\n",
    "    return r * u ** (1 / n) / np.sqrt(np.sum(x ** 2, 1, keepdims=True)) * x\n",
    "\n",
    "\n",
    "def sphere_replace(individual, radius_w, radius_b):\n",
    "    for layer in individual.model.layers:\n",
    "        if type(layer) not in layers_available_for_evolution:\n",
    "            continue\n",
    "\n",
    "        weights = layer.trainable_weights[0]\n",
    "        indexes = np.argwhere(np.random.random(size=weights.shape) < 2)\n",
    "        values_to_change = weights.numpy()\n",
    "        weights.scatter_nd_update(indexes, values_to_change.reshape(-1) +\n",
    "                                  get_random_samples_in_n_sphere(np.prod(values_to_change.shape), radius_w, 1)[0])\n",
    "\n",
    "        biases = layer.trainable_weights[1]\n",
    "        indexes = np.argwhere(np.random.random(size=biases.shape) < 2)\n",
    "        values_to_change = biases.numpy()\n",
    "        biases.scatter_nd_update(indexes, values_to_change.reshape(-1) +\n",
    "                                 get_random_samples_in_n_sphere(np.prod(values_to_change.shape), radius_b, 1)[0])\n",
    "\n",
    "\n",
    "def local_random_search(iterations, t=None):\n",
    "    nn = Individual(layers_format, loss)\n",
    "    best_nn = [evaluate(nn, train_feature, train_label), Individual(layers_format, loss).assign(nn)]\n",
    "    i = 1\n",
    "    start = time.time()\n",
    "    while i < iterations or (t is not None and time.time() - start < t):\n",
    "        w, b = Individual.weights_and_biases(best_nn[1].model)\n",
    "        new_nn = Individual(layers_format, loss, weights=w, biases=b)\n",
    "        sphere_replace(new_nn, 0.15, 0.15)\n",
    "        loss_value = evaluate(new_nn, train_feature, train_label)\n",
    "        if loss_value <= best_nn[0]:\n",
    "            best_nn[0] = loss_value\n",
    "            best_nn[1].assign(new_nn)\n",
    "        i += 1\n",
    "    print(i)\n",
    "    return best_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c4c13-88b9-4de8-a90a-8d48286e7ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss, best_nn = pure_random_search(100, 900)\n",
    "print('Best train loss:', best_loss)\n",
    "print('Best test loss:', evaluate(best_nn, test_feature, test_label))\n",
    "best_nn.model.save('best_neural_network_pure_rs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4249792-b2ae-46b3-b4e9-32bf764ffdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss, best_nn = local_random_search(100, 900)\n",
    "print('Best train loss:', best_loss)\n",
    "print('Best test loss:', evaluate(best_nn, test_feature, test_label))\n",
    "best_nn.model.save('best_neural_network_local_rs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a7acd-7bff-4105-8d74-ea5f8654131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_weights_biases(model):\n",
    "    w, b = Individual.weights_and_biases(model)\n",
    "    fcts = [np.min, np.max, np.sum]\n",
    "    w_stats = [np.inf, 0, 0]\n",
    "    b_stats = [np.inf, 0, 0]\n",
    "    b_n = w_n = 0\n",
    "    for w_val in w:\n",
    "        w_val = w_val.numpy()\n",
    "        w_n += len(w_val)\n",
    "        for i, op in enumerate(fcts):\n",
    "            w_stats[i] = op([w_stats[i], op(w_val)])\n",
    "    for b_val in b:\n",
    "        b_val = b_val.numpy()\n",
    "        b_n += len(b_val)\n",
    "        for i, op in enumerate(fcts):\n",
    "            b_stats[i] = op([b_stats[i], op(b_val)])\n",
    "\n",
    "    print(*w_stats[:-1], w_stats[-1]/w_n)\n",
    "    print(*b_stats[:-1], b_stats[-1]/b_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f5cd5b-3dab-4170-ac49-d264f4c2fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('best_neural_network_local_rs')\n",
    "stats_weights_biases(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bf78ba-07aa-4b47-be82-4e142edf418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plot(model.predict(test_feature[:2500]), test_label[:2500],\n",
    "          model.predict(train_feature[:5000]), train_label[:5000],\n",
    "         (0.5, 0.5), 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f74335-33ca-4bbb-9a6d-de8bb4973232",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
